---
- name: Deploy Loki Helm chart
  become: true
  tags:
    - molecule-idempotence-notest
  kubernetes.core.helm:
    name: loki
    chart_ref: loki
    chart_repo_url: https://grafana.github.io/helm-charts
    chart_version: '{{ observability_loki_chart_version }}'
    release_namespace: prometheus
    create_namespace: true
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    values:
      loki:
        # Disabling auth sets single tenant mode.
        auth_enabled: false
        # Setting replication factor and storage type to enable monolithic mode.
        commonConfig:
          replication_factor: 1
        storage:
          type: filesystem
      singleBinary:
        replicas: 1
        extraEnv:
          - name: JAEGER_AGENT_HOST
            value: collector-collector
          - name: JAEGER_SAMPLER_TYPE
            value: const
          - name: JAEGER_SAMPLER_PARAM
            value: '1'
      monitoring:
        # Disable self monitoring and Grafana Agent because Loki's logs are already
        # being collected by FluentBit.
        selfMonitoring:
          enabled: false
          grafanaAgent:
            installOperator: false
      # Chart test requires self monitoring which is disabled.
      test:
        enabled: false

- name: Deploy Prometheus Operator Helm chart
  become: true
  tags:
    - molecule-idempotence-notest
  kubernetes.core.helm:
    name: prometheus
    chart_ref: kube-prometheus-stack
    chart_repo_url: https://prometheus-community.github.io/helm-charts
    chart_version: '{{ observability_kube_prometheus_stack_chart_version }}'
    release_namespace: prometheus
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    wait: true
    values:
      # Disabled because we are using K3s without etcd.
      kubeEtcd:
        enabled: false

      # Disabled because it requires mounting / of the root filesystem.
      nodeExporter:
        enabled: false

      prometheus:
        prometheusSpec:
          serviceMonitorSelector:
            matchLabels:
              prometheus: in-cluster
          podMonitorSelector:
            matchLabels:
              prometheus: in-cluster
          additionalScrapeConfigs:
            - job_name: opentelemetry-collector
              static_configs:
                - targets:
                    - collector-collector:9000

          storageSpec:
            volumeClaimTemplate:
              spec:
                resources:
                  requests:
                    storage: 10Gi
                volumeMode: Filesystem
                accessModes:
                  - ReadWriteOnce

      grafana:
        adminUser: '{{ observability_grafana_user }}'
        adminPassword: '{{ observability_grafana_password }}'

        additionalDataSources:
          - name: Prometheus
            type: prometheus
            url: http://prometheus-kube-prometheus-prometheus.prometheus:9090
            editable: false
          - name: Loki
            type: loki
            url: http://loki:3100
            editable: false
          - name: Tempo
            type: tempo
            url: http://tempo:3100
            editable: false

        grafana.ini:
          analytics:
            reporting_enabled: false

        persistence:
          enabled: true

        ingress:
          enabled: true

          annotations:
            cert-manager.io/cluster-issuer: letsencrypt

          hosts:
            - '{{ observability_grafana_host }}'

          tls:
            - secretName: grafana-tls
              hosts:
                - '{{ observability_grafana_host }}'

- name: Deploy Grafana Tempo
  become: true
  tags:
    - molecule-idempotence-notest
  kubernetes.core.helm:
    name: tempo
    chart_ref: tempo
    chart_repo_url: https://grafana.github.io/helm-charts
    chart_version: '{{ observability_tempo_chart_version }}'
    release_namespace: prometheus
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    values:
      persistence:
        enabled: true
      tempo:
        reportingEnabled: false
        metricsGenerator:
          enabled: true
          remoteWriteUrl: http://prometheus-kube-prometheus-prometheus:9090/api/v1/write

- name: Deploy OpenTelemetry Operator chart
  become: true
  tags:
    - molecule-idempotence-notest
  kubernetes.core.helm:
    name: opentelemetry
    chart_ref: opentelemetry-operator
    chart_repo_url: https://open-telemetry.github.io/opentelemetry-helm-charts
    chart_version: '{{ observability_opentelemetry_operator_chart_version }}'
    release_namespace: prometheus
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    wait: true

- name: Deploy ClusterRole for OpenTelemetry Collector Target Allocator
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: opentelemetry-collector-targetallocator
        labels:
          app.kubernetes.io/name: opentelemetry-collector
          app.kubernetes.io/component: targetallocator
          app.kubernetes.io/managed-by: ansible
          rbac.authorization.k8s.io/aggregate-to-admin: 'true'
          rbac.authorization.k8s.io/aggregate-to-edit: 'true'
          rbac.authorization.k8s.io/aggregate-to-view: 'true'
      rules:
        - apiGroups:
            - ''
          resources:
            - pods
            - services
          verbs:
            - get
            - watch
            - list
        - apiGroups:
            - discovery.k8s.io
          resources:
            - endpointslices
          verbs:
            - get
            - watch
            - list
        - apiGroups:
            - monitoring.coreos.com
          resources:
            - servicemonitors
            - podmonitors
          verbs:
            - get
            - watch
            - list

- name: Deploy ClusterRoleBinding for OpenTelemetry Collector Target Allocator
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: opentelemetry-collector-targetallocator
        labels:
          app.kubernetes.io/name: opentelemetry-collector
          app.kubernetes.io/component: targetallocator
          app.kubernetes.io/managed-by: ansible
      subjects:
        - kind: ServiceAccount
          name: collector-targetallocator
          namespace: prometheus
      roleRef:
        kind: ClusterRole
        name: opentelemetry-collector-targetallocator
        apiGroup: rbac.authorization.k8s.io

# OpenTelemetry Operator does not create a ServiceAccount with enough privileges.
# See https://github.com/open-telemetry/opentelemetry-operator/issues/1679
- name: Deploy ServiceAccount for OpenTelemetry Collector Target Allocator
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    namespace: prometheus
    definition:
      apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: collector-targetallocator
        namespace: prometheus
        labels:
          app.kubernetes.io/name: opentelemetry-collector
          app.kubernetes.io/component: targetallocator
          app.kubernetes.io/managed-by: ansible

- name: Deploy OpenTelemetry Collector
  become: true
  tags:
    - molecule-idempotence-notest
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    namespace: prometheus
    definition:
      apiVersion: opentelemetry.io/v1alpha1
      kind: OpenTelemetryCollector
      metadata:
        name: collector
        labels:
          app.kubernetes.io/name: opentelemetry-collector
          app.kubernetes.io/component: collector
          app.kubernetes.io/managed-by: ansible
      spec:
        mode: statefulset
        targetAllocator:
          enabled: true
          serviceAccount: collector-targetallocator
          prometheusCR:
            enabled: true
            serviceMonitorSelector: '{{ observability_service_monitor_selector }}'
            podMonitorSelector: '{{ observability_pod_monitor_selector }}'
        # The port for prometheus exporter is not exposed automatically.
        # See https://github.com/open-telemetry/opentelemetry-operator/issues/1689
        ports:
          - name: promexporter
            port: 9000
            protocol: TCP
        config: |
          receivers:
            otlp:
              protocols:
                grpc:
                http:
            jaeger:
              protocols:
                grpc:
                thrift_binary:
                thrift_compact:
                thrift_http:
            fluentforward:
              endpoint: 0.0.0.0:8006
            prometheus:
              config:
                scrape_configs: []
              target_allocator:
                endpoint: http://collector-targetallocator:80
                interval: 30s
                collector_id: $POD_NAME

          processors:
            attributes:
              actions:
                - action: insert
                  key: loki.format
                  value: raw
                - action: insert
                  key: loki.attribute.labels
                  value: stream, host, namespace, pod, container, component, app, instance

          exporters:
            otlp:
              endpoint: tempo:4317
              tls:
                insecure: true
            loki:
              endpoint: http://loki:3100/loki/api/v1/push
            prometheus:
              endpoint: 0.0.0.0:9000

          service:
            pipelines:
              traces:
                receivers: [otlp, jaeger]
                processors: []
                exporters: [otlp]
              logs:
                receivers: [otlp, fluentforward]
                processors: [attributes]
                exporters: [loki]
              metrics:
                receivers: [otlp, prometheus]
                processors: []
                exporters: [prometheus]

- name: Deploy OpenTelemetry Collector internal metrics PodMonitor
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    namespace: prometheus
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: PodMonitor
      metadata:
        name: opentelemetry-collector
        labels:
          app.kubernetes.io/name: opentelemetry-collector
          app.kubernetes.io/component: monitoring
          app.kubernetes.io/managed-by: ansible
          release: prometheus
      spec:
        podMetricsEndpoints:
          - port: metrics
        jobLabel: opentelemetry-collector
        namespaceSelector:
          matchNames:
            - prometheus
        selector:
          matchLabels:
            app.kubernetes.io/name: collector-collector
            app.kubernetes.io/component: opentelemetry-collector

- name: Deploy Fluent operator
  become: true
  tags:
    - molecule-idempotence-notest
  kubernetes.core.helm:
    name: fluent-operator
    chart_ref: >-
      {{ 'https://github.com/fluent/fluent-operator/releases/download/v%s/fluent-operator.tgz'
      | format(observability_fluent_operator_chart_version) }}
    release_namespace: prometheus
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    values:
      containerRuntime: containerd
      # Disable the default FluentBit pipeline because it does not fit our stack.
      kubernetes: false

- name: Deploy FluentBit config
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    namespace: prometheus
    definition:
      apiVersion: fluentbit.fluent.io/v1alpha2
      kind: ClusterFluentBitConfig
      metadata:
        name: config
        labels:
          app.kubernetes.io/name: fluent-bit
          app.kubernetes.io/component: config
          app.kubernetes.io/managed-by: ansible
      spec:
        inputSelector:
          matchLabels:
            fluentbit.fluent.io/enabled: 'true'
            fluentbit.fluent.io/mode: k8s
          filterSelector:
            matchLabels:
              fluentbit.fluent.io/enabled: 'true'
              fluentbit.fluent.io/mode: k8s
          outputSelector:
            matchLabels:
              fluentbit.fluent.io/enabled: 'true'
              fluentbit.fluent.io/mode: k8s

- name: Deploy FluentBit input config
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    namespace: prometheus
    definition:
      apiVersion: fluentbit.fluent.io/v1alpha2
      kind: ClusterInput
      metadata:
        name: tail
        labels:
          fluentbit.fluent.io/enabled: 'true'
          fluentbit.fluent.io/mode: k8s
          app.kubernetes.io/name: fluent-bit
          app.kubernetes.io/component: config
          app.kubernetes.io/managed-by: ansible
      spec:
        tail:
          tag: kube.*
          path: /var/log/containers/*.log
          multilineParser: cri
          refreshIntervalSeconds: 10
          memBufLimit: 5MB
          skipLongLines: true
          db: /fluent-bit/tail/pos.db
          dbSync: Normal

- name: Deploy FluentBit filter config
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    namespace: prometheus
    definition:
      apiVersion: fluentbit.fluent.io/v1alpha2
      kind: ClusterFilter
      metadata:
        name: kubernetes
        labels:
          fluentbit.fluent.io/enabled: 'true'
          fluentbit.fluent.io/mode: k8s
          app.kubernetes.io/name: fluent-bit
          app.kubernetes.io/component: config
          app.kubernetes.io/managed-by: ansible
      spec:
        match: kube.*
        filters:
          - kubernetes:
              labels: true
              annotations: true
          - nest:
              operation: lift
              nestedUnder: kubernetes
              addPrefix: kubernetes_
          - nest:
              operation: lift
              nestedUnder: kubernetes_labels
              addPrefix: labels_kubernetes_
          - modify:
              rules:
                - copy:
                    kubernetes_pod_name: pod
                    kubernetes_container_name: container
                    kubernetes_namespace_name: namespace
                    kubernetes_host: host
                    labels_kubernetes_app.kubernetes.io/component: component
                    labels_kubernetes_app.kubernetes.io/instance: instance
                    labels_kubernetes_app.kubernetes.io/name: app
          - nest:
              operation: nest
              wildcard:
                - labels_kubernetes_*
              nestUnder: kubernetes_labels
              removePrefix: labels_kubernetes_
          - nest:
              operation: nest
              wildcard:
                - kubernetes_*
              nestUnder: kubernetes
              removePrefix: kubernetes_

- name: Deploy FluentBit output config
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    namespace: prometheus
    definition:
      apiVersion: fluentbit.fluent.io/v1alpha2
      kind: ClusterOutput
      metadata:
        name: opentelemetry
        labels:
          fluentbit.fluent.io/enabled: 'true'
          fluentbit.fluent.io/mode: k8s
          app.kubernetes.io/name: fluent-bit
          app.kubernetes.io/component: config
          app.kubernetes.io/managed-by: ansible
      spec:
        matchRegex: (?:kube|service)\.(.*)
        forward:
          host: collector-collector
          port: 8006

- name: Deploy FluentBit
  become: true
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    namespace: prometheus
    definition:
      apiVersion: fluentbit.fluent.io/v1alpha2
      kind: FluentBit
      metadata:
        name: fluent-bit
        namespace: prometheus
        labels:
          app.kubernetes.io/name: fluent-bit
          app.kubernetes.io/component: bit
          app.kubernetes.io/managed-by: ansible
      spec:
        image: kubesphere/fluent-bit:v1.8.11
        positionDB:
          hostPath:
            path: /var/lib/fluent-bit/
        resources:
          requests:
            cpu: 10m
            memory: 25Mi
          limits:
            cpu: 500m
            memory: 200Mi
        fluentBitConfigName: config
        tolerations:
          - operator: Exists
